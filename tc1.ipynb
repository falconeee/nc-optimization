{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bc41771",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0425c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "from scipy.optimize import differential_evolution\n",
    "import pygad\n",
    "from TfELM.Layers.ELMLayer import ELMLayer\n",
    "from TfELM.Models.ELMModel import ELMModel\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0568b98",
   "metadata": {},
   "source": [
    "# Wine Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00f884e",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6abf8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine = pd.read_csv(\"wine.csv\", sep=\",\", decimal=\".\")\n",
    "print(df_wine.shape)\n",
    "\n",
    "print(\"Wine 1:\", df_wine[df_wine['Wine']==1].shape[0])\n",
    "print(\"Wine 2:\", df_wine[df_wine['Wine']==2].shape[0])\n",
    "print(\"Wine 3:\", df_wine[df_wine['Wine']==3].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f576a6",
   "metadata": {},
   "source": [
    "## Split train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432c8681",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_wine.drop(columns=[\"Wine\"])\n",
    "y = df_wine[\"Wine\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,random_state=42)\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8ab408",
   "metadata": {},
   "source": [
    "## Apply z-score in data train and data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd92dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a01cd8",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8d2677",
   "metadata": {},
   "source": [
    "##### All features and default values for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efae193",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(random_state=42).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"*** Baseline MLPClassifier ***\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred),2))\n",
    "print(\"Precision:\", round(precision_score(y_test, y_pred, average='weighted'),2))\n",
    "print(\"F1 Score:\", round(f1_score(y_test, y_pred, average='weighted'),2))\n",
    "print(\"Recall:\", round(recall_score(y_test, y_pred, average='weighted'),2))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba932e92",
   "metadata": {},
   "source": [
    "## Differential Evolution (DE) + Backpropagation (BP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb00193c",
   "metadata": {},
   "source": [
    "Melhores configurações encontradas:\n",
    "- Features selecionadas: ['Alcohol', 'Malic.acid', 'Ash', 'Acl', 'Mg', 'Flavanoids', 'Proanth', 'Color.int', 'Hue', 'Proline']\n",
    "- Número de camadas ocultas: 4\n",
    "- Número de neurônios por camada: 75\n",
    "- Taxa de aprendizado: 0.01008\n",
    "- random_seed = 42\n",
    "- max_iter = 200\n",
    "\n",
    "Acurácia final no conjunto de teste: 0.9556"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af8076",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X.columns.tolist()\n",
    "n_features = X_train_scaled.shape[1]\n",
    "\n",
    "def fitness(individual):\n",
    "    feature_mask = individual[:n_features] > 0.5\n",
    "    if not any(feature_mask):\n",
    "        return 10.0  # penaliza se nenhuma feature for selecionada\n",
    "\n",
    "    n_layers = int(np.clip(round(individual[n_features]), 1, 5))\n",
    "    n_neurons = int(np.clip(round(individual[n_features + 1]), 10, 100))\n",
    "    learning_rate = individual[n_features+2]             # 0.0001 a 0.1\n",
    "\n",
    "    hidden_layer_sizes = tuple([n_neurons] * n_layers) # cria tupla com o número de camadas ocultas e com mesmo número de neurônios\n",
    "    X_sel = X_train_scaled[:, feature_mask] # seleciona as features com base no mask\n",
    "    # MLPClassifier com os parâmetros selecionados, por padrão camada de entrada e saída são definidas automaticamente\n",
    "    # Camada de entrada tem o mesmo número de features selecionadas e a camada de saída tem o mesmo número de classes\n",
    "    clf = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes,\n",
    "                        learning_rate_init=learning_rate,\n",
    "                        max_iter=200)\n",
    "\n",
    "    try:\n",
    "        score = cross_val_score(clf, X_sel, y_train, cv=3, scoring='accuracy').mean() # média da acurácia em 3 folds\n",
    "    except:\n",
    "        return 10.0\n",
    "\n",
    "    return 1.0 - score  # minimizar o erro\n",
    "\n",
    "# DE configuration\n",
    "bounds = [(0, 1)] * n_features + [(1, 5), (10, 100), (0.0001, 0.1)]\n",
    "\n",
    "result = differential_evolution(\n",
    "    fitness, bounds, maxiter=20, popsize=50, disp=True,\n",
    "    mutation=(0.5,1), recombination=0.95, strategy='best1bin'\n",
    ")\n",
    "\n",
    "# Avaliate the best individual found in test data\n",
    "best_individual = result.x\n",
    "selected_features = best_individual[:n_features] > 0.5\n",
    "n_layers_best = int(round(best_individual[n_features]))\n",
    "n_neurons_best = int(round(best_individual[n_features+1]))\n",
    "lr_best = best_individual[n_features+2]\n",
    "\n",
    "print(\"\\nMelhores configurações encontradas:\")\n",
    "print(f\"- Features selecionadas: {[feature_names[i] for i in range(n_features) if selected_features[i]]}\")\n",
    "print(f\"- Número de camadas ocultas: {n_layers_best}\")\n",
    "print(f\"- Número de neurônios por camada: {n_neurons_best}\")\n",
    "print(f\"- Taxa de aprendizado: {lr_best:.5f}\")\n",
    "\n",
    "# Treina modelo final com os melhores parâmetros\n",
    "clf_final = MLPClassifier(\n",
    "    hidden_layer_sizes=(n_neurons_best,) * n_layers_best,\n",
    "    learning_rate_init=lr_best,\n",
    "    max_iter=200,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train_sel = X_train_scaled[:, selected_features]\n",
    "X_test_sel = X_test_scaled[:, selected_features]\n",
    "\n",
    "clf_final.fit(X_train_sel, y_train)\n",
    "accuracy_test = clf_final.score(X_test_sel, y_test)\n",
    "print(f\"\\nAcurácia final no conjunto de teste: {accuracy_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01d8330",
   "metadata": {},
   "source": [
    "## Differential Evolution (DE) + Extreme Learning Machine (ELM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2900382",
   "metadata": {},
   "source": [
    "Melhores configurações encontradas:\n",
    "- Features selecionadas: ['Alcohol', 'Ash', 'Acl', 'Phenols', 'Flavanoids', 'Proanth', 'Color.int', 'Hue', 'Proline']\n",
    "- Número de neurônios ocultos (ELM): 488\n",
    "\n",
    "Acurácia final no conjunto de teste com ELM: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ed6115",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train_scaled.shape[1]\n",
    "\n",
    "# A função fitness agora otimiza apenas a seleção de features e o número de neurônios\n",
    "def fitness(individual):\n",
    "    feature_mask = individual[:n_features] > 0.5\n",
    "    if not np.any(feature_mask):\n",
    "        return 10.0\n",
    "\n",
    "    # O único hiperparâmetro do ELM a ser otimizado é o número de neurônios.\n",
    "    n_neurons = int(round(individual[n_features]))\n",
    "    \n",
    "    X_sel = X_train_scaled[:, feature_mask]\n",
    "    \n",
    "    # MLPClassifier -> ELMClassifier\n",
    "    # 'number_neurons' é o parâmetro para o número de neurônios da camada oculta\n",
    "    # Initialize an Extreme Learning Machine (ELM) layer\n",
    "    elm = ELMLayer(number_neurons=n_neurons, activation='relu')\n",
    "    # Create an ELM model using the trained ELM layer\n",
    "    clf = ELMModel(elm)\n",
    "\n",
    "    try:\n",
    "        score = cross_val_score(clf, X_sel, y_train, cv=3, scoring='accuracy').mean()\n",
    "    except Exception as e:\n",
    "        # Penaliza se houver qualquer erro durante o treinamento/validação\n",
    "        return 10.0\n",
    "\n",
    "    return 1.0 - score  # O objetivo continua sendo minimizar o erro (1 - acurácia)\n",
    "\n",
    "# bounds apenas para seleção de features e número de neurônios\n",
    "bounds = [(0, 1)] * n_features + [(10, 1000)]\n",
    "\n",
    "result = differential_evolution(\n",
    "    fitness, bounds, maxiter=20, popsize=50, disp=True,\n",
    "    mutation=(0.7, 1.5), recombination=0.7, strategy='best1bin'\n",
    ")\n",
    "\n",
    "best_individual = result.x\n",
    "selected_features = best_individual[:n_features] > 0.5\n",
    "n_neurons_best = int(round(best_individual[n_features]))\n",
    "\n",
    "print(\"\\nMelhores configurações encontradas:\")\n",
    "print(f\"- Features selecionadas: {[feature_names[i] for i in range(n_features) if selected_features[i]]}\")\n",
    "print(f\"- Número de neurônios ocultos (ELM): {n_neurons_best}\")\n",
    "\n",
    "elm = ELMLayer(number_neurons=n_neurons_best, activation='relu')\n",
    "clf_final = ELMModel(elm)\n",
    "\n",
    "X_train_sel = X_train_scaled[:, selected_features]\n",
    "X_test_sel = X_test_scaled[:, selected_features]\n",
    "\n",
    "clf_final.fit(X_train_sel, y_train)\n",
    "accuracy_test = clf_final.score(X_test_sel, y_test)\n",
    "print(f\"\\nAcurácia final no conjunto de teste com ELM: {accuracy_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7d7eb6",
   "metadata": {},
   "source": [
    "### Rosebrook function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf12e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(x):\n",
    "    # Example: Rosenbrock function\n",
    "    return sum(100.0 * (x[1:] - x[:-1]**2.0)**2.0 + (1 - x[:-1])**2.0)\n",
    "\n",
    "# Define bounds for the variables\n",
    "bounds = [(-5, 5), (-5, 5), (-5, 5)]  # For a 2-variable problem\n",
    "\n",
    "# Perform the optimization\n",
    "result = differential_evolution(objective_function, bounds, maxiter=20, popsize=50, disp=True,\n",
    "    mutation=(0.7,1.5), recombination=0.6, strategy='rand1bin'\n",
    ")\n",
    "\n",
    "print(\"Optimal solution:\", result.x)\n",
    "print(\"Minimum value:\", result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55b7965",
   "metadata": {},
   "source": [
    "### Rastrigin Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d849d01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(x):\n",
    "    A = 10\n",
    "    return A * len(x) + sum(xi**2 - A * np.cos(2 * np.pi * xi) for xi in x)\n",
    "\n",
    "# Define os limites para cada variável (geralmente em [-5.12, 5.12])\n",
    "bounds = [(-5.12, 5.12), (-5.12, 5.12),  (-5.12, 5.12)] # Problema com 2 variáveis\n",
    "\n",
    "# Otimização\n",
    "result = differential_evolution(\n",
    "    objective_function,\n",
    "    bounds,\n",
    "    maxiter=20,\n",
    "    popsize=50,\n",
    "    mutation=(0.7, 1.5),\n",
    "    recombination=0.6,\n",
    "    strategy='rand1bin',\n",
    "    disp=True\n",
    ")\n",
    "\n",
    "print(\"Optimal solution:\", result.x)\n",
    "print(\"Minimum value:\", result.fun)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40404cd",
   "metadata": {},
   "source": [
    "### Griewank Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c817463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(x):\n",
    "    sum_sq = np.sum(x**2) / 4000\n",
    "    prod_cos = np.prod(np.cos(x / np.sqrt(np.arange(1, len(x) + 1))))\n",
    "    return sum_sq - prod_cos + 1\n",
    "\n",
    "# Define os limites para cada variável (geralmente em [-600, 600])\n",
    "bounds = [(-600, 600), (-600, 600), (-600,600)]  # Problema com 2 variáveis\n",
    "\n",
    "# Otimização com Differential Evolution\n",
    "result = differential_evolution(\n",
    "    objective_function,\n",
    "    bounds,\n",
    "    maxiter=20,\n",
    "    popsize=50,\n",
    "    mutation=(0.7, 1.5),\n",
    "    recombination=0.6,\n",
    "    strategy='rand1bin',\n",
    "    disp=True\n",
    ")\n",
    "\n",
    "print(\"Optimal solution:\", result.x)\n",
    "print(\"Minimum value:\", result.fun)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ee3bfb",
   "metadata": {},
   "source": [
    "### Schwefel Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa81271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(x):\n",
    "    return 418.9829 * len(x) - np.sum(x * np.sin(np.sqrt(np.abs(x))))\n",
    "\n",
    "# Domínio padrão para Schwefel\n",
    "bounds = [(-500, 500), (-500, 500), (-500,500)]  # 2 variáveis\n",
    "\n",
    "# Otimização com Differential Evolution\n",
    "result = differential_evolution(\n",
    "    objective_function,\n",
    "    bounds,\n",
    "    maxiter=20,\n",
    "    popsize=50,\n",
    "    mutation=(0.7, 1.5),\n",
    "    recombination=0.6,\n",
    "    strategy='rand1bin',\n",
    "    disp=True\n",
    ")\n",
    "\n",
    "print(\"Optimal solution:\", result.x)\n",
    "print(\"Minimum value:\", result.fun)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212c6efd",
   "metadata": {},
   "source": [
    "## Genetic Algorithm (GA) + Backpropagation (BP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a096ecea",
   "metadata": {},
   "source": [
    "Melhores configurações encontradas:\n",
    "- Fitness (Acurácia em CV): 1.0000\n",
    "- Features selecionadas: ['Alcohol', 'Ash', 'Acl', 'Mg', 'Flavanoids', 'Nonflavanoid.phenols', 'Color.int', 'Hue', 'Proline']\n",
    "- Número de camadas ocultas: 1\n",
    "- Número de neurônios por camada: 58\n",
    "- Taxa de aprendizado: 0.05117\n",
    "\n",
    "Acurácia final no conjunto de teste: 1.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da08e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train_scaled.shape[1]\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "def fitness_func(ga_instance, solution, solution_idx):\n",
    "    # Decodifica a solução (indivíduo)\n",
    "    feature_mask = np.array(solution[:n_features]).astype(bool)\n",
    "    \n",
    "    # Penaliza se nenhuma característica for selecionada\n",
    "    if not np.any(feature_mask):\n",
    "        return -1.0  # PyGAD maximiza, então um valor baixo para penalizar\n",
    "\n",
    "    # Arredonda os valores para garantir que sejam inteiros\n",
    "    n_layers = int(round(solution[n_features]))\n",
    "    n_neurons = int(round(solution[n_features + 1]))\n",
    "    learning_rate = solution[n_features + 2]\n",
    "\n",
    "    hidden_layer_sizes = tuple([n_neurons] * n_layers)\n",
    "    X_sel = X_train_scaled[:, feature_mask]\n",
    "\n",
    "    clf = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes,\n",
    "                        learning_rate_init=learning_rate,\n",
    "                        max_iter=200\n",
    "                        )\n",
    "\n",
    "    try:\n",
    "        # cross-validation para uma avaliação mais robusta\n",
    "        score = cross_val_score(clf, X_sel, y_train, cv=3, scoring='accuracy').mean()\n",
    "    except ValueError:\n",
    "        # penaliza a solução\n",
    "        return -1.0\n",
    "\n",
    "    # PyGAD maximiza a função de fitness por padrão, então a acurácia é retornada diretamente.\n",
    "    return score\n",
    "\n",
    "# Define o espaço de busca para os genes\n",
    "gene_space = [ [0, 1] for _ in range(n_features) ] + [ {'low': 1, 'high': 3, 'step': 1}, {'low': 10, 'high': 100, 'step': 1}, {'low': 0.0001, 'high': 0.1} ]\n",
    "\n",
    "num_genes = len(gene_space)\n",
    "ga_instance = pygad.GA(\n",
    "    num_generations=50,          # Equivalente a 'maxiter' ou 'ngen'\n",
    "    num_parents_mating=10,       # Número de soluções selecionadas como pais\n",
    "    sol_per_pop=50,              # Tamanho da população\n",
    "    num_genes=num_genes,              \n",
    "    fitness_func=fitness_func,   # Função de fitness a ser maximizada\n",
    "    gene_space=gene_space,       # Define o espaço de busca para cada gene\n",
    "    parent_selection_type=\"tournament\", # Seleção 'tournament'\n",
    "    crossover_type=\"two_points\", # Crossover de dois pontos\n",
    "    mutation_type=\"random\",      # Mutação aleatória dentro do 'gene_space'\n",
    "    mutation_probability=0.6   # Probabilidade de mutação\n",
    ")\n",
    "ga_instance.run()\n",
    "ga_instance.plot_fitness()\n",
    "\n",
    "best_solution, best_solution_fitness, best_solution_idx = ga_instance.best_solution()\n",
    "\n",
    "selected_features = best_solution[:n_features].astype(bool)\n",
    "n_layers_best = int(round(best_solution[n_features]))\n",
    "n_neurons_best = int(round(best_solution[n_features+1]))\n",
    "lr_best = best_solution[n_features+2]\n",
    "\n",
    "print(\"\\nMelhores configurações encontradas:\")\n",
    "print(f\"- Fitness (Acurácia em CV): {best_solution_fitness:.4f}\")\n",
    "print(f\"- Features selecionadas: {[feature_names[i] for i in range(n_features) if selected_features[i]]}\")\n",
    "print(f\"- Número de camadas ocultas: {n_layers_best}\")\n",
    "print(f\"- Número de neurônios por camada: {n_neurons_best}\")\n",
    "print(f\"- Taxa de aprendizado: {lr_best:.5f}\")\n",
    "\n",
    "# Treina o modelo final com os melhores parâmetros\n",
    "clf_final = MLPClassifier(\n",
    "    hidden_layer_sizes=(n_neurons_best,) * n_layers_best,\n",
    "    learning_rate_init=lr_best,\n",
    "    max_iter=200, # Pode ser aumentado para o treino final\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train_sel = X_train_scaled[:, selected_features]\n",
    "X_test_sel = X_test_scaled[:, selected_features]\n",
    "\n",
    "clf_final.fit(X_train_sel, y_train)\n",
    "accuracy_test = clf_final.score(X_test_sel, y_test)\n",
    "print(f\"\\nAcurácia final no conjunto de teste: {accuracy_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b88cc4d",
   "metadata": {},
   "source": [
    "## Genetic Algorithm (GA) + Extreme Learning Machine (ELM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219b654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train_scaled.shape[1]\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "def fitness_func(ga_instance, solution, solution_idx):\n",
    "    # Decodifica a solução (indivíduo)\n",
    "    feature_mask = np.array(solution[:n_features]).astype(bool)\n",
    "    \n",
    "    # Penaliza se nenhuma característica for selecionada\n",
    "    if not np.any(feature_mask):\n",
    "        return -1.0  # PyGAD maximiza, então um valor baixo para penalizar\n",
    "\n",
    "    # Arredonda os valores para garantir que sejam inteiros\n",
    "    n_neurons = int(round(solution[n_features]))\n",
    "\n",
    "    X_sel = X_train_scaled[:, feature_mask]\n",
    "\n",
    "    elm = ELMLayer(number_neurons=n_neurons, activation='relu')\n",
    "    # Create an ELM model using the trained ELM layer\n",
    "    clf = ELMModel(elm)\n",
    "\n",
    "    try:\n",
    "        # cross-validation para uma avaliação mais robusta\n",
    "        score = cross_val_score(clf, X_sel, y_train, cv=3, scoring='accuracy').mean()\n",
    "    except ValueError:\n",
    "        # penaliza a solução\n",
    "        return -1.0\n",
    "\n",
    "    # PyGAD maximiza a função de fitness por padrão, então a acurácia é retornada diretamente.\n",
    "    return score\n",
    "\n",
    "# Define o espaço de busca para os genes\n",
    "for _ in range(n_features):\n",
    "    gene_space.append({'low': 0, 'high': 1, 'step': 1})\n",
    "# Gene para o número de neurônios (inteiro de 10 a 1000)\n",
    "gene_space.append({'low': 10, 'high': 1000, 'step': 1})\n",
    "\n",
    "num_genes = len(gene_space)\n",
    "ga_instance = pygad.GA(\n",
    "    num_generations=50,          # Equivalente a 'maxiter' ou 'ngen'\n",
    "    num_parents_mating=10,       # Número de soluções selecionadas como pais\n",
    "    sol_per_pop=50,              # Tamanho da população\n",
    "    num_genes=num_genes,              \n",
    "    fitness_func=fitness_func,   # Função de fitness a ser maximizada\n",
    "    gene_space=gene_space,       # Define o espaço de busca para cada gene\n",
    "    parent_selection_type=\"tournament\", # Seleção 'tournament'\n",
    "    crossover_type=\"two_points\", # Crossover de dois pontos\n",
    "    mutation_type=\"random\",      # Mutação aleatória dentro do 'gene_space'\n",
    "    mutation_probability=0.6   # Probabilidade de mutação\n",
    ")\n",
    "ga_instance.run()\n",
    "ga_instance.plot_fitness()\n",
    "\n",
    "best_solution, best_solution_fitness, best_solution_idx = ga_instance.best_solution()\n",
    "\n",
    "selected_features = best_solution[:n_features].astype(bool)\n",
    "n_neurons_best = int(round(best_solution[n_features]))\n",
    "\n",
    "print(\"\\nMelhores configurações encontradas:\")\n",
    "print(f\"- Fitness (Acurácia em CV): {best_solution_fitness:.4f}\")\n",
    "print(f\"- Features selecionadas: {[feature_names[i] for i in range(n_features) if selected_features[i]]}\")\n",
    "print(f\"- Número de neurônios da camada oculta: {n_neurons_best}\")\n",
    "\n",
    "# Treina o modelo final com os melhores parâmetros\n",
    "elm = ELMLayer(number_neurons=n_neurons_best, activation='relu')\n",
    "clf_final = ELMModel(elm)\n",
    "\n",
    "X_train_sel = X_train_scaled[:, selected_features]\n",
    "X_test_sel = X_test_scaled[:, selected_features]\n",
    "\n",
    "clf_final.fit(X_train_sel, y_train)\n",
    "accuracy_test = clf_final.score(X_test_sel, y_test)\n",
    "print(f\"\\nAcurácia final no conjunto de teste: {accuracy_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe2ba6c",
   "metadata": {},
   "source": [
    "# Diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9ef48b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
